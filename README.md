# Асинхронный парсер документации Python

Этот проект реализует асинхронный парсер данных со страницы с общей информацией о Python Enhancement Proposal (PEP) (https://peps.python.org/). Парсер осуществляет переход по ссылкам и собирает данные о каждом PEP. Полученные данные подготавливаются и сохраняются в два файла формата csv в папку results.

## Установка и использование
1. Клонирование репозитория

```
git clone https://github.com/dagedarr/scrapy_parser_pep.git

cd bs4_parser_pep
```
Если вы не используете Git, вы можете просто скачать исходный код репозитория в ZIP-архиве и распаковать его на свой компьютер.

2. Создание виртуального окружения и активация
```
python -m venv venv
source venv/bin/activate
```

3. Установка зависимостей
```
pip install -r requirements.txt
```

4. Запустить парсер из командной строки:
```
scrapy crawl pep
```

# Результат работы
Результатом работы парсера будет создание двух файлов:
1. ``results/pep_ДатаВремя.csv``
Содержит номер, название и статус для кажого PEP;
2. ``results/status_summary_ДатаВремя.csv`` 
Содержит сводку по статусам PEP: 
сколько найдено документов в каждом статусе и общее количество всех PEP.

# Готово!
Вы успешно установили парсер дданных со страницы PEP и готовы использовать его для получения данных из официальной документации Python.
